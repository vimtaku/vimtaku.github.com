<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[vimtaku blog]]></title>
  <link href="http://vimtaku.github.io/atom.xml" rel="self"/>
  <link href="http://vimtaku.github.io/"/>
  <updated>2014-02-16T19:32:56+09:00</updated>
  <id>http://vimtaku.github.io/</id>
  <author>
    <name><![CDATA[vimtaku]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[日経Linux 2月号を読んだ]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/16/nikkei-linux-feb/"/>
    <updated>2014-02-16T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/16/nikkei-linux-feb</id>
    <content type="html"><![CDATA[<h2 id="section">概要</h2>
<p><a href="http://www.amazon.co.jp/%E6%97%A5%E7%B5%8C-Linux-%E3%83%AA%E3%83%8A%E3%83%83%E3%82%AF%E3%82%B9-2014%E5%B9%B4-02%E6%9C%88%E5%8F%B7/dp/B00H8X84E6">日経Linux 2月号(2014)</a>
に、カーネルの特集記事があったので買って読んでみた。<br />
今まで知らなかった部分とか、便利そうなことについて、以下に記載する。  </p>

<h2 id="section-1">メモリ管理</h2>
<p>buddy システム, スラブアロケータについて書かれていた。<br />
この本よりもっと詳しく書かれたページを発見したのでコチラを参照。<br />
<a href="http://www.coins.tsukuba.ac.jp/~yas/coins/os2-2011/2012-01-17/">http://www.coins.tsukuba.ac.jp/~yas/coins/os2-2011/2012-01-17/</a></p>

<h2 id="systemtap">systemtap</h2>
<p>system tap とは <a href="https://access.redhat.com/site/ja/node/289453">https://access.redhat.com/site/ja/node/289453</a> にある通り  </p>

<blockquote><p>実行している Linux カーネルで簡易情報を取得できるようにする革新的なツールです。</p></blockquote>
<p>である。  </p>

<h3 id="install-centos">install 方法(@CentOS)</h3>
<p>vagrant で建てた CentOS を使ってやってみる。<br />
Vagrantfile 的に<br />
config.vm.box = “Berkshelf-CentOS-6.3-x86_64-minimal”<br />
この box を使っている人は以下の通りでインストールできると思います。  </p>

<div>
  <pre><code class="bash">sudo yum -y install systemtap
cd /tmp
wget http://debuginfo.centos.org/6/x86_64/kernel-debuginfo-common-x86_64-2.6.32-279.el6.x86_64.rpm
wget http://debuginfo.centos.org/6/x86_64/kernel-debug-debuginfo-2.6.32-279.el6.x86_64.rpm
sudo yum install kernel-debuginfo-common-x86_64-2.6.32-279.el6.x86_64.rpm
sudo yum install kernel-debug-debuginfo-2.6.32-279.el6.x86_64.rpm

# これで stap がつかえる
stap

## 追記
(これだと probe.kernel が使えないっぽい.. 要調査。)</code></pre>
</div>

<p>あとは
<a href="http://sourceware.org/systemtap/examples/">http://sourceware.org/systemtap/examples/</a><br />
ここから<br />
vm.tracepoints.stp や, sched_switch.stp を落として来て実行できる。  </p>

<p>(参考)<br />
<a href="http://stts.hatenablog.com/entry/20090614/1244952417">http://stts.hatenablog.com/entry/20090614/1244952417</a>  </p>

<h2 id="section-2">プロセスのメモリ割付について</h2>
<p>/proc/[processId]/maps (これをメモリーマップと呼ぶ。)を参照すれば、どのようにメモリが割り付けられているかがわかる。  </p>

<div>
  <pre><code class="bash">vi hoge.c
-----
#include &lt;stdio.h&gt;

int main(void) {
  char hoge[4096] = &quot;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&quot;;

printf(&quot;sleep start\n&quot;);
  sleep(500000);
printf(&quot;sleep stop\n&quot;);
  return 0;
}

ps aux | grep a.out
vagrant  19157  0.0  0.0   3928   408 pts/1    S+   04:41   0:00 ./a.out
vagrant  19164  0.0  0.0 107456   948 pts/0    S+   04:42   0:00 grep a.out


cd /proc/
cat /proc/19157/maps

00400000-00402000 r-xp 00000000 fd:00 3590                               /tmp/a.out
00601000-00602000 rw-p 00001000 fd:00 3590                               /tmp/a.out
7fdf912e5000-7fdf91470000 r-xp 00000000 fd:00 3071                       /lib64/libc-2.12.so
7fdf91470000-7fdf9166f000 ---p 0018b000 fd:00 3071                       /lib64/libc-2.12.so
7fdf9166f000-7fdf91673000 r--p 0018a000 fd:00 3071                       /lib64/libc-2.12.so
7fdf91673000-7fdf91674000 rw-p 0018e000 fd:00 3071                       /lib64/libc-2.12.so
7fdf91674000-7fdf91679000 rw-p 00000000 00:00 0
7fdf91679000-7fdf91699000 r-xp 00000000 fd:00 3437                       /lib64/ld-2.12.so
7fdf9188e000-7fdf91891000 rw-p 00000000 00:00 0
7fdf91896000-7fdf91898000 rw-p 00000000 00:00 0
7fdf91898000-7fdf91899000 r--p 0001f000 fd:00 3437                       /lib64/ld-2.12.so
7fdf91899000-7fdf9189a000 rw-p 00020000 fd:00 3437                       /lib64/ld-2.12.so
7fdf9189a000-7fdf9189b000 rw-p 00000000 00:00 0
7fff2a0dc000-7fff2a0f1000 rw-p 00000000 00:00 0                          [stack]
7fff2a1b4000-7fff2a1b5000 r-xp 00000000 00:00 0                          [vdso]
ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]</code></pre>
</div>

<p>下から見ると、 systemcall が呼ばれる領域(カーネル仮想空間)があるのと、 stack が積まれる領域があるのと、<br />
shared object がリンクされている領域と、 テキスト(プログラム)が格納されている領域があるのが見て取れる。  </p>

<p>左端から、仮想アドレス、アクセス属性、データオフセット、 デバイスのメジャー番号とマイナー番号、 inode, ファイル名とのこと。  </p>

<h2 id="section-3">カーネル時計</h2>
<p>Linux カーネルは 起動時には、PC の内蔵時計を使用するが、それ移行は独自のカーネル時計を使用する。<br />
ミリ秒からナノ秒の処理が必要であるため。  </p>

<h2 id="io">I/Oスケジューラー</h2>
<p>入出力するブロックデータを並び替えて入出力を高速化できるもの。  </p>

<p><a href="http://city.hokkai.or.jp/~hachikun/IOScheduler.html">http://city.hokkai.or.jp/~hachikun/IOScheduler.html</a><br />
<a href="[http://city.hokkai.or.jp/~hachikun/IOScheduler.html]">http://www.valinux.co.jp/technologylibrary/document/linuxkarnel/cfq0001/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[jekyll から octopress に10 分で移行する]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/14/octopress/"/>
    <updated>2014-02-14T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/14/octopress</id>
    <content type="html"><![CDATA[<h2 id="section">背景</h2>
<p>デザインが見づらいって言われたので辛くなったから、<br />
octopress にノリで移行してみた。<br />
当方、 jekyll-bootstrap を使っていて、 octopress も普通に jekyll 使っているので<br />
問題なく移行できると思ったら移行できた。  </p>

<h2 id="section-1">手順</h2>
<p>大体こんなかんじでいける。空気さえ読めれば行ける感じ。  </p>

<div>
  <pre><code class="bash">git clone git://github.com/imathis/octopress.git octopress
cd octopress/
bundle install
rake install
rake preview
rake -T
vim config.rb
rake preview
rake setup_github_pages

## Rakefile の L269 の git push を -f するようにした。すでにレポジトリがあったから。
vim Rakefile

rake deploy

cp -a $HOME/jekyll-bootstrap/_posts/* .

## JB setup を記事に埋め込んでいるのがあったのでそれをケア(互換性のため)
mkdir $HOME/octopress/source/includes/JB
cp -a $HOME/jekyll-bootstrap/_includes/JB/setup $HOME/octopress/source/includes/JB</code></pre>
</div>

<h2 id="section-2">ちなみに</h2>
<p>テーマはコチラを使わせてもらった。<br />
<a href="http://zespia.tw/Octopress-Theme-Slash/">http://zespia.tw/Octopress-Theme-Slash/</a><br />
how to install 通りにやれば適用できる。  </p>

<p>Octopress テーマ集みたいなのはコチラ。<br />
<a href="http://opthemes.com/">http://opthemes.com/</a>  </p>

<h2 id="section-3">参考資料</h2>

<p><a href="http://joelmccracken.github.io/entries/octopress-is-pretty-sweet/">http://joelmccracken.github.io/entries/octopress-is-pretty-sweet/</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[今更 Solr 入門]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/13/solr-sample/"/>
    <updated>2014-02-13T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/13/solr-sample</id>
    <content type="html"><![CDATA[
<h2 id="toc">TOC</h2>
<ul id="markdown-toc">
  <li><a href="#toc">TOC</a></li>
  <li><a href="#section">この記事について</a></li>
  <li><a href="#section-1">予備知識</a>    <ul>
      <li><a href="#apache-solr-">Apache Solr とは</a></li>
      <li><a href="#lucene-">Lucene とは</a></li>
    </ul>
  </li>
  <li><a href="#section-2">スキーマを作ってみよう</a>    <ul>
      <li><a href="#section-3">フィールドタイプについて</a></li>
      <li><a href="#section-4">フィールドについて</a>        <ul>
          <li><a href="#section-5">テキストフィールドの定義</a></li>
          <li><a href="#section-6">ダイナミックフィールド</a></li>
          <li><a href="#section-7">ユニークキーフィールド</a></li>
          <li><a href="#section-8">コピーフィールド</a></li>
        </ul>
      </li>
      <li><a href="#core-admin--core-">core admin で core を作成</a></li>
    </ul>
  </li>
  <li><a href="#section-9">サンプルデータを入れてみよう</a></li>
  <li><a href="#dihdataimporthandler-">DIH(DataImportHandler) について</a>    <ul>
      <li><a href="#solr-config-">solr config に記述する</a></li>
      <li><a href="#mysql--connector-">mysql の connector をダウンロードして設置</a></li>
      <li><a href="#mysql--db-data-configxml-">mysql の設定, db-data-config.xml の設定など</a></li>
    </ul>
  </li>
  <li><a href="#deltaquery-">deltaQuery について</a>    <ul>
      <li><a href="#deltaquery--parentdeltaquery-">deltaQuery と parentDeltaQuery の関係</a></li>
    </ul>
  </li>
  <li><a href="#dih--javascript-">DIH の直前で Javascript でデータを加工する</a>    <ul>
      <li><a href="#updatehandler--updatechain">UpdateHandler と UpdateChain</a></li>
      <li><a href="#section-10">なんかうまくいかない場合</a></li>
    </ul>
  </li>
  <li><a href="#url">参考URL</a></li>
</ul>

<h2 id="section">この記事について</h2>
<p>今更ながら Solr に興味が出てきたので、自分用にまとめてみる。<br />
あくまで自分用なので、ある程度わかっている人じゃないと本記事は無意味です。恐縮ながら。<br />
前提として、 この記事は <a href="http://www.amazon.co.jp/Apache-Solr%E5%85%A5%E9%96%80-~%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E3%82%BD%E3%83%BC%E3%82%B9%E5%85%A8%E6%96%87%E6%A4%9C%E7%B4%A2%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%B3-Software-Design/dp/4774161632">改訂新版 Apache Solr入門 ~オープンソース全文検索エンジン</a> を読みながら進めた。   </p>

<p>まずは、予備知識として Apache Solr とはなにか、 Lucene とはなにかについて書く。<br />
次に、スキーマを作って、サンプルデータ を 手動でのデータインポートで index に登録する手順について書く。<br />
手動でのデータインポートは大変なので、mysql からデータをインポートするクローラ(DIH)について書く。
最後に、 MySQL にある json を保存するカラムのデータを、 Javascript を使って整形し、 index に保存することについて書く。  </p>

<h2 id="section-1">予備知識</h2>

<h3 id="apache-solr-">Apache Solr とは</h3>
<p>全文検索システムである。<br />
全文検索エンジン Lucene をベースに、管理画面やキャッシュ、クラスタリングなどの機能がある。<br />
ちなみに Java で書かれている。<br />
<a href="http://ja.wikipedia.org/wiki/Apache_Solr">http://ja.wikipedia.org/wiki/Apache_Solr</a></p>

<h3 id="lucene-">Lucene とは</h3>
<blockquote><p>Lucene（ルシーン）は、Javaで記述された全文検索ソフトウェアである。<br />あらかじめ蓄積した大量のデータから、指定したキーワードを探し出す機能を持つ。Javaのクラスライブラリとして提供される。</p></blockquote>
<p><a href="http://ja.wikipedia.org/wiki/Lucene">http://ja.wikipedia.org/wiki/Lucene</a>
なるほど。</p>

<h2 id="section-2">スキーマを作ってみよう</h2>
<p>スキーマを作って、サンプルデータを入れてみる。<br />
ここでは、 料理人が複数いて、自分の料理をうるみたいなものを想定する。<br />
Solr の schema.xml で、スキーマを定義することができる。  </p>

<p>以下に、 schema.xml の fileds の設定例を載せる。  </p>
<div>
  <pre><code class="xml">&lt;fields&gt;
    &lt;field name=&quot;recipe_id&quot;   type=&quot;int&quot;     indexed=&quot;true&quot; stored=&quot;true&quot; required=&quot;true&quot;/&gt;
    &lt;field name=&quot;chef&quot;        type=&quot;text_ja&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
    &lt;field name=&quot;recipe_name&quot; type=&quot;text_ja&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
    &lt;field name=&quot;genre&quot;       type=&quot;text_ja&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;true&quot;/&gt;
    &lt;field name=&quot;price&quot;       type=&quot;int&quot;     indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
    &lt;field name=&quot;_version_&quot;   type=&quot;long&quot;    indexed=&quot;true&quot; stored=&quot;true&quot;/&gt;
  &lt;/fields&gt;</code></pre>
</div>

<h3 id="section-3">フィールドタイプについて</h3>
<ul>
  <li>fieldType は自分で xml を用いて定義することができる</li>
  <li>それらの名前付けとかには習慣がある</li>
  <li>基本的な型については定義されているので、それを利用する</li>
</ul>

<h3 id="section-4">フィールドについて</h3>

<h4 id="section-5">テキストフィールドの定義</h4>
<ul>
  <li>name は filed 名</li>
  <li>type は filedType</li>
  <li>indexed は、 このフィールドを検索対象、ソート対象、 ファセット対象にするか(true:する)</li>
  <li>stored は、 このフィールドの値をそのまま index するか(true:する)</li>
  <li>required は、 必須かどうか</li>
  <li>multivalued は、 複数値を持てるかどうか</li>
  <li>omitNorms は、 検索したドキュメントの長さによる重み付け
    <ul>
      <li>(短ければ当然、見つけるものに近いのでポイントが高く、逆に長ければ、それにヒットする確率が高いので値は低い。)</li>
    </ul>
  </li>
</ul>

<h4 id="section-6">ダイナミックフィールド</h4>
<ul>
  <li>動的にフィールド名が決定するもの</li>
  <li>schema.xml を変更しなくても、そのフィールド名を登録したり検索したりすることができるようになる</li>
</ul>

<h4 id="section-7">ユニークキーフィールド</h4>
<ul>
  <li>文書内で unique に特定できるようにするフィールド</li>
  <li>差分更新したい場合には必須</li>
  <li>指定はオプション</li>
  <li>
    <uniquekey>url</uniquekey>
  </li>
</ul>

<h4 id="section-8">コピーフィールド</h4>
<ul>
  <li>ドキュメントへのインデックス登録時に copyField の source から dest へコピーする</li>
  <li>dest に同じものを複数指定する場合は multiValued が true である必要がある</li>
</ul>

<h3 id="core-admin--core-">core admin で core を作成</h3>
<p>collection1 をコピーして, schema.xml を編集。<br />
elevate が評価されてダメっぽかったのでコメントアウト。<br />
すると、うまく load できた。</p>

<h2 id="section-9">サンプルデータを入れてみよう</h2>
<p>だいたいこんなかんじの data.json を用意して</p>
<div>
  <pre><code class="json">[                                                                              
{                                                                              
    &quot;recipe_id&quot;:&quot;1&quot;,                                                           
    &quot;chef&quot;:&quot;vimtaku&quot;,                                                          
    &quot;recipe_name&quot;:&quot;vim の炒めもの&quot;,                                            
    &quot;genre&quot;:[&quot;和食&quot;, &quot;洋食&quot;],                                                  
    &quot;price&quot;:980                                                                
},                                                                             
{                                                                              
    &quot;recipe_id&quot;:&quot;2&quot;,                                                           
    &quot;chef&quot;:&quot;noro&quot;,                                                             
    &quot;recipe_name&quot;:&quot;emacs 焼き&quot;,                                                
    &quot;genre&quot;:[&quot;和食&quot;, &quot;中華&quot;],                                                  
    &quot;price&quot;:500                                                                
},                                                                             
{                                                                              
    &quot;recipe_id&quot;:&quot;3&quot;,                                                           
    &quot;chef&quot;:&quot;sublime&quot;,                                                          
    &quot;recipe_name&quot;:&quot;sublime 揚げ&quot;,                                              
    &quot;genre&quot;:[&quot;洋食&quot;],                                                          
    &quot;price&quot;:250                                                                
}                                                                              
]</code></pre>
</div>

<div>
  <pre><code class="bash">curl 'http://localhost:8983/solr/vimtaku/update/json?commit=true' --data-binary @data.json -H 'Content-type:application/json;charset:utf-8'</code></pre>
</div>

<p>これで データ登録が完了する。  </p>

<h2 id="dihdataimporthandler-">DIH(DataImportHandler) について</h2>
<p>DIH は DataSource, EntityProccssor, そして設定ファイル(data‐config.xml) から成る。<br />
DIH を使うための設定は、 solrconfig.xml と DIHの設定ファイル data―config にある。  </p>

<h3 id="solr-config-">solr config に記述する</h3>
<div>
  <pre><code class="xml">&lt;requestHandler name=&quot;/dataimport&quot; class=&quot;org.apache.solr.handler.dataimport.DatalmportHandler&quot;&gt;
&lt;lst name=&quot;defaults&quot;&gt;
  &lt;str name=&quot;config&quot;&gt;db-data-config.xml&lt;/str&gt;
&lt;/lst&gt;
&lt;/requestHandler&gt;</code></pre>
</div>

<h3 id="mysql--connector-">mysql の connector をダウンロードして設置</h3>
<p>mysql-connector-java-5.1.29-bin.jar を <a href="http://dev.mysql.com/downloads/connector/j/">http://dev.mysql.com/downloads/connector/j/</a>から落としてきて
dist 以下に設置する。</p>

<h3 id="mysql--db-data-configxml-">mysql の設定, db-data-config.xml の設定など</h3>
<p>そしてだいたいこんなかんじに設置する。 mysql は localhost の 3306 番で動いているものとし、<br />
solrsample っていう database があるものとする。 password は hogehoge。  </p>

<div>
  <pre><code class="bash">diff --git a/conf/db-data-config.xml b/conf/db-data-config.xml
new file mode 100644
index 0000000..c758319
--- /dev/null
+++ b/conf/db-data-config.xml
@@ -0,0 +1,24 @@
+&lt;dataConfig&gt;
+    &lt;dataSource type=&quot;JdbcDataSource&quot; driver=&quot;com.mysql.jdbc.Driver&quot;
+        url=&quot;jdbc:mysql://localhost:3306/solrsample&quot;
+        user=&quot;vimtaku&quot; password=&quot;hogehoge&quot;/&gt;
+    &lt;document&gt;
+        &lt;entity name=&quot;recipe_mst&quot; pk=&quot;recipe_id&quot;
+            query=&quot;select * from recipe_mst&quot;
+            deltaImportQuery=&quot;SELECT * FROM recipe_mst WHERE recipe_id = ${dataimporter.delta.recipe_id}&quot;
+            deltaQuery=&quot;select recipe_id from recipe_mst WHERE updated_at &gt;= '${dataimporter.last_index_time}'&quot;&gt;
+            &lt;field column=&quot;recipe_id&quot; name=&quot;recipe_id&quot; /&gt;
+            &lt;field column=&quot;recipe_name&quot; name=&quot;recipe_name&quot; /&gt;
+            &lt;field column=&quot;price&quot; name=&quot;price&quot; /&gt;
+            &lt;entity name=&quot;recipe_genre_rel&quot;
+                query=&quot;select * from recipe_genre_rel where recipe_id = '${recipe_mst.recipe_id}'&quot;&gt;
+                &lt;entity name=&quot;genre_mst&quot; query=&quot;select * from genre_mst where genre_id = '${recipe_genre_rel.genre_id}'&quot;&gt;
+                    &lt;field column=&quot;name&quot; name=&quot;genre&quot; /&gt;
+                &lt;/entity&gt;
+            &lt;/entity&gt;
+            &lt;entity name=&quot;chef_mst&quot; query=&quot;select * from chef_mst where chef_id = '${recipe_mst.chef_id}'&quot;&gt;
+                &lt;field column=&quot;name&quot; name=&quot;chef&quot; /&gt;
+            &lt;/entity&gt;
+        &lt;/entity&gt;
+    &lt;/document&gt;
+&lt;/dataConfig&gt;
diff --git a/conf/solrconfig.xml b/conf/solrconfig.xml
index 00b7555..2d19133 100644
--- a/conf/solrconfig.xml
+++ b/conf/solrconfig.xml
@@ -84,6 +84,9 @@
   &lt;lib dir=&quot;../../../contrib/velocity/lib&quot; regex=&quot;.*\.jar&quot; /&gt;
   &lt;lib dir=&quot;../../../dist/&quot; regex=&quot;solr-velocity-\d.*\.jar&quot; /&gt;

+  &lt;lib dir=&quot;../../../dist/&quot; regex=&quot;solr-dataimporthandler-.*\.jar&quot; /&gt;
+  &lt;lib dir=&quot;../../../dist/&quot; regex=&quot;mysql.*\.jar&quot; /&gt;
+
   &lt;!-- an exact 'path' can be used instead of a 'dir' to specify a
        specific jar file.  This will cause a serious error to be logged
        if it can't be loaded.
@@ -1513,6 +1516,15 @@
   &lt;/requestHandler&gt;


+  &lt;requestHandler name=&quot;/dataimport&quot;
+      class=&quot;org.apache.solr.handler.dataimport.DataImportHandler&quot;&gt;
+      &lt;lst name=&quot;defaults&quot;&gt;
+          &lt;str name=&quot;config&quot;&gt;db-data-config.xml&lt;/str&gt;</code></pre>
</div>

<p>だいたいこんなかんじで、管理画面から /dataimport で full-import するといける。</p>

<h2 id="deltaquery-">deltaQuery について</h2>
<p>差分 update(delta-import) のとき、deltaQuery がまず、実行される。
deltaQuery は どんなに nest が深くても実行される(たぶん)。</p>

<h3 id="deltaquery--parentdeltaquery-">deltaQuery と parentDeltaQuery の関係</h3>
<ul>
  <li>deltaQuery で mysql のレコードがヒットした場合に、 parentDeltaQuery が呼び出される</li>
  <li>parentDeltaQuery では ${chef_mst.chef_id} のように、 deltaQuery でヒットしたものが使える</li>
  <li>parentDeltaQuery で、 pk の 値を select するようにしておく。</li>
  <li>pk のある entity に、
    <ul>
      <li>deltaImportQuery 属性がなくて query 属性がある場合には where pk = ‘’ としてクエリが実行され再登録される模様</li>
      <li>deltaImportQuery 属性がある場合にはそのクエリが実行される。</li>
    </ul>
  </li>
</ul>

<p>例えば</p>

<div>
  <pre><code class="xml">&lt;dataConfig&gt;
    &lt;dataSource type=&quot;JdbcDataSource&quot; driver=&quot;com.mysql.jdbc.Driver&quot;
        url=&quot;jdbc:mysql://localhost:3306/solrsample&quot;
        user=&quot;vimtaku&quot; password=&quot;hogehoge&quot;/&gt;
    &lt;document&gt;
        &lt;entity name=&quot;recipe_mst&quot; pk=&quot;recipe_id&quot;
            query=&quot;select * from recipe_mst&quot;
            deltaImportQuery=&quot;SELECT * FROM recipe_mst WHERE recipe_id = ${dataimporter.delta.recipe_id}&quot;
            deltaQuery=&quot;select recipe_id from recipe_mst WHERE updated_at &gt;= '${dataimporter.last_index_time}'&quot;
            &gt;
            &lt;field column=&quot;recipe_id&quot; name=&quot;recipe_id&quot; /&gt;
            &lt;field column=&quot;recipe_name&quot; name=&quot;recipe_name&quot; /&gt;
            &lt;field column=&quot;price&quot; name=&quot;price&quot; /&gt;
            &lt;entity name=&quot;recipe_genre_rel&quot;
                query=&quot;select * from recipe_genre_rel where recipe_id = '${recipe_mst.recipe_id}'&quot;&gt;
                &lt;entity name=&quot;genre_mst&quot; query=&quot;select * from genre_mst where genre_id = '${recipe_genre_rel.genre_id}'&quot;&gt;
                    &lt;field column=&quot;name&quot; name=&quot;genre&quot; /&gt;
                &lt;/entity&gt;
            &lt;/entity&gt;
            &lt;entity name=&quot;chef_mst&quot; pk=&quot;chef_id&quot;
                query=&quot;select * from chef_mst where chef_id = '${recipe_mst.chef_id}'&quot;
                deltaQuery=&quot;select chef_id from chef_mst where chef_id = 1&quot;
                parentDeltaQuery=&quot;select recipe_id from chef_mst where chef_id = ${chef_mst.chef_id} limit 1&quot;
                &gt;
                &lt;field column=&quot;name&quot; name=&quot;chef&quot; /&gt;
            &lt;/entity&gt;
        &lt;/entity&gt;
    &lt;/document&gt;
&lt;/dataConfig&gt;</code></pre>
</div>

<p>こうなっていた場合、<br />
deltaQuery=”select chef_id from chef_mst where chef_id = 1”<br />
これでヒットした chef_id を元に<br />
parentDeltaQuery=”select recipe_id from chef_mst where chef_id = ${chef_mst.chef_id} limit 1”<br />
が実行されて、<br />
deltaImportQuery=”SELECT * FROM recipe_mst WHERE recipe_id = ${dataimporter.delta.recipe_id}”<br />
これが実行される。  </p>

<h2 id="dih--javascript-">DIH の直前で Javascript でデータを加工する</h2>

<h3 id="updatehandler--updatechain">UpdateHandler と UpdateChain</h3>
<p>UpdateHandler と DIH の仕組みはこの図のようになっている。  </p>

<p><img src="http://gyazo.com/47cc999c6d1a7a31ed9c2bdd0080ce59.png" />
(改訂版 Apache Solr 入門より引用。)</p>

<p>DIH とは疎になっていて、 UpdateHandler はどの requestHandler でも使えるように見える。  </p>

<p>設定には<a href="https://github.com/vimtaku/solr_sample/commit/85c7439d239d55e3344cc20a32461536c3201eb8">この差分</a>
を参照。  </p>

<p>これを使えば、json のカラムからとった json を parse して multiValue なカラムに登録などができる。  </p>

<h3 id="section-10">なんかうまくいかない場合</h3>
<p>キャッシュされたデータを更新するとたまに更新されない。<br />
自分は一回 core を削除、 $SOLR_HOME の data ディレクトリを rm -rf している。<br />
もっといい、データ削除(もしくはいれかえ)の方法知っている人は教えて下さい。。  </p>

<h2 id="url">参考URL</h2>
<p><a href="http://ja.wikipedia.org/wiki/Lucene">http://ja.wikipedia.org/wiki/Lucene</a><br />
<a href="http://wiki.apache.org/solr/DataImportHandler">http://wiki.apache.org/solr/DataImportHandler</a><br />
<a href="http://ochien.seesaa.net/article/153191074.html">http://ochien.seesaa.net/article/153191074.html</a><br />
<a href="http://d.hatena.ne.jp/kudzu/20110513/1305313247">http://d.hatena.ne.jp/kudzu/20110513/1305313247</a><br />
<a href="http://d.hatena.ne.jp/bowez/20100405#p2">http://d.hatena.ne.jp/bowez/20100405#p2</a>  </p>

<p>_</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[docker_boot2docker_port_foward]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/10/docker-boot2docker-port-foward/"/>
    <updated>2014-02-10T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/10/docker-boot2docker-port-foward</id>
    <content type="html"><![CDATA[
<h2 id="os-x-108--docker">OS X 10.8 公式サポートで話題の Docker</h2>

<p><a href="http://qiita.com/kanekoa/items/cf3cabb23da69c609002">これ</a>をもとにとりあえず docker client を準備,<br />
docker server を建てた。  </p>

<h2 id="mac--localhost--telnet-11211--memcached-">mac の localhost に telnet 11211 したら memcached につながるようにしたい</h2>

<p><a href="https://www.docker.io/learn/dockerfile/level2/">https://www.docker.io/learn/dockerfile/level2/</a>
これをもとに Dockerfile を作った。 ここでは ubuntu を元にした vimtaku/memcached_1 とした。  </p>

<p>Dockefile</p>
<div>
  <pre><code class="bash"># Memcached
#
# VERSION       2.2

# use the ubuntu base image provided by dotCloud
FROM ubuntu

MAINTAINER Victor Coisne victor.coisne@dotcloud.com

# make sure the package repository is up to date
RUN echo &quot;deb http://archive.ubuntu.com/ubuntu precise main universe&quot; &gt; /etc/apt/sources.list
RUN apt-get update

# install memcached
RUN apt-get install -y memcached

# Launch memcached when launching the container
ENTRYPOINT [&quot;memcached&quot;]

# run memcached as the daemon user
USER daemon

# expose memcached port
EXPOSE 11211</code></pre>
</div>

<div>
  <pre><code class="bash">docker build -t vimtaku/memcached_1 - &lt; Dockerfile</code></pre>
</div>

<p>これでとりあえず memcached な image を作れる。  </p>

<div>
  <pre><code class="bash">docker run -p 11211:11211 vimtaku/memcached_1</code></pre>
</div>

<p>これで boot2docker -&gt; ubuntu が立つ。  </p>

<h2 id="section">追記(2014/02/13)</h2>
<p>成功法っぽいのを発見した。<br />
恥ずかしながら ssh port fowarding が -L オプションで できるっていうのを
<a href="http://motemen.hatenablog.com/entry/2014/02/11/Dockerfile_%E3%82%92%E5%85%83%E3%81%AB%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%82%92%E8%B5%B0%E3%82%89%E3%81%9B%E3%81%A6%E3%83%AD%E3%83%BC%E3%82%AB%E3%83%AB%E3%81%AB%E3%83%9D%E3%83%BC%E3%83%88%E3%82%92">このブログ記事</a>
で初めて知った。  </p>

<p>まだ、やってないけど  </p>
<div>
  <pre><code class="bash">ssh -L 11211:localhost:11211 -p 2022 root@localhost</code></pre>
</div>

<p>とかすれば、 ssh port fowarding できるので、以下の手順は不要。</p>

<p>追記終わり。</p>

<h2 id="section-1">とりあえず確認するには</h2>

<p>とりあえず確認するには<br />
boot2docker ssh して ifconfig | grep -A4 docker0 すると<br />
172…. のような IP が見える。<br />
そこに対して telnet すると ちゃんと疎通できてる。<br />
ちなみに telnet localhost 11211 しても同様。  </p>

<p>あとは mac -&gt; boot2docker に 11211 疎通できればよい。<br />
ぐぐったら
<a href="http://fogstack.wordpress.com/2014/02/09/docker-on-osx-port-forwarding/">http://fogstack.wordpress.com/2014/02/09/docker-on-osx-port-forwarding/</a> の記事が見つかったのでほぼこれの通りに、</p>

<div>
  <pre><code class="bash">boot2docker down
したあと
VBoxManage modifyvm &quot;boot2docker-vm&quot; --natpf1 &quot;guestmemcached,tcp,,11211,,11211&quot;
boot2docker up
docker run -d -p 11211:11211 vimtaku/memcached_1</code></pre>
</div>

<p>これで mac から telnet localhost 11211 で行けた。たぶん。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2014/2/9]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/09/life-feb-9/"/>
    <updated>2014-02-09T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/09/life-feb-9</id>
    <content type="html"><![CDATA[
<h2 id="section">土日振り返り</h2>
<p>雪うざい。地味に perfect ruby を進めた。<br />
ruby 力が2くらい上がった。気がする。  </p>

<h2 id="section-1">勉強途中経過</h2>

<h3 id="section-2">進んでない</h3>
<ul>
  <li>rails tutorial 6 までやった</li>
</ul>

<h2 id="section-3">読書途中経過</h2>

<h3 id="section-4">進んだ</h3>
<ul>
  <li>パーフェクトルビー15章まで読んだ
    <ul>
      <li>手を動かしながら ver</li>
    </ul>
  </li>
</ul>

<h3 id="section-5">積んでる</h3>
<ul>
  <li>詳解UNIXプログラミング第7章まで読んだ</li>
  <li>オペレーティングシステム 6章まで読んだ</li>
  <li>Webエンジニアのためのデータベース技術［実践］入門 7章まで読んだ</li>
  <li>ネットワークはなぜつながるのか?</li>
  <li>chef-solo 入門 #23 まで読んだ(どっかで手を動かしながらやる)</li>
</ul>

<h3 id="section-6">読み終えた</h3>
<ul>
  <li>(2014/2/8)プログラマの数学</li>
  <li>(2014/2/6)(一周目、さらっと)[改訂新版] Apache Solr入門 ~オープンソース全文検索エンジン</li>
  <li>(2014/1/26)マスタリングTCP/IP 入門第5版 とりあえず読み切った</li>
  <li>(2014/1/13)読む筋トレ</li>
  <li>(2014/1/8)ザ・コーチ 最高の自分に出会える「目標の達人ノート」</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2月の solr には雪も full]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/08/life-feb-8/"/>
    <updated>2014-02-08T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/08/life-feb-8</id>
    <content type="html"><![CDATA[
<h2 id="section">先週の振り返り</h2>
<p>先週は solr 祭りだった。<br />
solr は存在くらいしか知らなかったけど、非常によく出来たソフトウェアで<br />
これを使いこなせれば(使い方を知っていれば)非常によい価値を<br />
提供できる気がした。  </p>

<p>先々週はあんまり何やったか覚えていない。<br />
そういや 先週は docker とかめっちゃいいなと思ってたところだった。<br />
あとで触ってみよう。  </p>

<p>ところで東京のくせに雪とか降るのは生意気だと思う(北から目線。  </p>

<h2 id="section-1">勉強途中経過</h2>

<h3 id="section-2">進んでない</h3>
<ul>
  <li>rails tutorial 6 までやった</li>
</ul>

<h2 id="section-3">読書途中経過</h2>

<h3 id="section-4">進んだ</h3>
<ul>
  <li>詳解UNIXプログラミング第7章まで読んだ</li>
  <li>パーフェクトルビー10章まで読んだ
    <ul>
      <li>手を動かしながら ver</li>
    </ul>
  </li>
</ul>

<h3 id="section-5">積んでる</h3>
<ul>
  <li>オペレーティングシステム 6章まで読んだ</li>
  <li>Webエンジニアのためのデータベース技術［実践］入門 7章まで読んだ</li>
  <li>ネットワークはなぜつながるのか?</li>
  <li>chef-solo 入門 #23 まで読んだ(どっかで手を動かしながらやる)</li>
</ul>

<h3 id="section-6">読み終えた</h3>
<ul>
  <li>(2014/2/8)プログラマの数学</li>
  <li>(2014/2/6)(一周目、さらっと)[改訂新版] Apache Solr入門 ~オープンソース全文検索エンジン</li>
  <li>(2014/1/26)マスタリングTCP/IP 入門第5版 とりあえず読み切った</li>
  <li>(2014/1/13)読む筋トレ</li>
  <li>(2014/1/8)ザ・コーチ 最高の自分に出会える「目標の達人ノート」</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[イチロー]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/08/ichiro/"/>
    <updated>2014-02-08T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/08/ichiro</id>
    <content type="html"><![CDATA[
<h2 id="section">名言</h2>

<h3 id="by-">小さいことを積み重ねるのが、とんでもないところへ行くただひとつの道だと思っています。(by イチロー)</h3>

<p>はい、がんばりましょう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker の概要をしらべて触ってみた]]></title>
    <link href="http://vimtaku.github.io/blog/2014/02/02/what-is-docker/"/>
    <updated>2014-02-02T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/02/02/what-is-docker</id>
    <content type="html"><![CDATA[
<h2 id="toc">TOC</h2>
<ul id="markdown-toc">
  <li><a href="#toc">TOC</a></li>
  <li><a href="#section">はじめに</a></li>
  <li><a href="#docker-">docker とは</a></li>
  <li><a href="#lxc-">LXC とは</a></li>
  <li><a href="#aufs-union-fs-">aufs, Union FS とは</a>    <ul>
      <li><a href="#union-mount">union mount</a></li>
      <li><a href="#section-1">読み込み</a></li>
      <li><a href="#section-2">書き込み</a></li>
      <li><a href="#section-3">削除</a></li>
    </ul>
  </li>
  <li><a href="#github-">github 的な要素</a>    <ul>
      <li><a href="#section-4">出来上がりイメージ</a></li>
    </ul>
  </li>
  <li><a href="#section-5">所感</a></li>
  <li><a href="#section-6">参考文献</a></li>
</ul>

<h2 id="section">はじめに</h2>
<p>この記事では Docker について自分なりに理解するために調べたことをまとめる。<br />
Docker の tutorial は command line を ブラウザで実際に叩くところまでできるようになっているので、<br />
非常にわかりやすく入門できる。なので、 tutorial に関してはそっちをやったほうが良い。<br />
この記事は Docker ってこんな感じのやつなんだーってのが伝わればばいいなと思う。<br />
(ちなみに まだ Docker 歴は1日)</p>

<h2 id="docker-">docker とは</h2>
<p>LXC と aufs と github のようなものをうまくくみ合わせて提供される<br />
仮想化ソフトウェアだ。  </p>

<h2 id="lxc-">LXC とは</h2>
<p>Linux Container のこと。  </p>

<p><a href="http://gihyo.jp/admin/column/01/vm/2011/lxc_container">http://gihyo.jp/admin/column/01/vm/2011/lxc_container</a>によれば、  </p>
<blockquote><p>LXCの基本技術となるのが「コンテナ」と呼ばれる一種のリソース管理システムです。ファイルシステムの他，ホスト名やプロセス，ネットワークソケットなどのカーネルが扱うさまざまなリソースの管理テーブルを個々に用意し，これをコンテナごとに管理することで，コンテナごとに独立したOSのように動作させることができます。</p></blockquote>
<p>とある。<br />
また、カーネルの機能である <a href="http://ja.wikipedia.org/wiki/Cgroups">Cgroups</a> の説明をみれば非常によく理解できた。  </p>

<h2 id="aufs-union-fs-">aufs, Union FS とは</h2>
<p>ここに、 Union mount と Union type file system の資料がある。<br />
非常にわかりやすい説明だった。ここに、 aufs の説明もある。結構古いけど。。<br />
<a href="http://www.oreilly.co.jp/community/blog/2010/02/union-mount-uniontype-fs-part-1.html">http://www.oreilly.co.jp/community/blog/2010/02/union-mount-uniontype-fs-part-1.html</a>
ちょっとだけ簡単に自分用にまとめる。  </p>

<h3 id="union-mount">union mount</h3>
<p>filesystem A と filesystem B をマウントして、それぞれが file A, file B を同じディレクトリで持っていたとすると、<br />
union mount をつかったとき、fileA, file B の両方のファイルが見える。  </p>

<h3 id="section-1">読み込み</h3>
<p>open システムコールとかを通して呼ぶと、 union 機能が上から順に読んでいけば、差分的に一番新しいものを読める。<br />
両方のファイルシステムが fileA を持っていて、その内容がちがう場合、filesystem の mount の優先度(レイヤー順?)で<br />
どちらの filesystem の fileA が見えるか変わるんだと思う。  </p>

<h3 id="section-2">書き込み</h3>
<p>なんらかを書き込んで差分ができたとき、 上位ディスクとは違うものを保証しなければならないため、<br />
上位ディスクのものをコピーして書き込む。だからコピーオンライト。<br />
でもこの場合は、 copy-up と呼ばれて、プロセス fork でいうそれとは区別されている模様。  </p>

<h3 id="section-3">削除</h3>
<p>ファイルが削除されても、上位ディスクには存在しているため、事実上削除ができない。<br />
なので 特別なファイルを作成することで 消えたように見せる。(DB で言う論理削除みたいなもんだと認識)<br />
whiteout という。  </p>

<h2 id="github-">github 的な要素</h2>
<p><a href="https://index.docker.io">index.docker.io</a> レポジトリに image を push できる。<br />
memcached を <a href="https://www.docker.io/learn/dockerfile/">Dockerfile によって image を作る tutorial</a> があるので、それをやった。<br />
それでできた Dockerfile  を使って repository に push した例を以下に示す。<br />
ちなみに、 <a href="https://index.docker.io/account/">https://index.docker.io/account/</a> にあらかじめ登録しておいた。  </p>

<div>
  <pre><code class="bash">vagrant@ubuntu-12:~$ docker login
Username: vimtaku
Password:
Email: ******@gmail.com
Login Succeeded

vagrant@ubuntu-12:~$ docker build -t vimtaku/memcached_sample - &lt; Dockerfile

vagrant@ubuntu-12:~$ docker images
REPOSITORY                 TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
vimtaku/memcached_sample   latest              242bd405025e        22 seconds ago      217.1 MB
run_memcached              latest              5f1cda03f61c        17 hours ago        217.1 MB
memcached                  latest              9166d484dda8        17 hours ago        217.1 MB
brand_new_memcached        latest              7bdd82d0abf7        20 hours ago        217.1 MB
memcached_new              latest              c18168a45363        20 hours ago        245.5 MB
ubuntu                     12.10               426130da57f7        7 days ago          127.6 MB
ubuntu                     quantal             426130da57f7        7 days ago          127.6 MB
ubuntu                     10.04               8589d4e9c7c6        7 days ago          139.6 MB
ubuntu                     lucid               8589d4e9c7c6        7 days ago          139.6 MB
ubuntu                     12.04               72e10143e54a        7 days ago          125.9 MB
ubuntu                     latest              72e10143e54a        7 days ago          125.9 MB
ubuntu                     precise             72e10143e54a        7 days ago          125.9 MB
ubuntu                     13.10               721f07d19f96        7 days ago          144.6 MB
ubuntu                     saucy               721f07d19f96        7 days ago          144.6 MB
ubuntu                     13.04               476aa49de636        7 days ago          133.6 MB
ubuntu                     raring              476aa49de636        7 days ago          133.6 MB

vagrant@ubuntu-12:~$ docker push vimtaku/memcached_sample
The push refers to a repository [vimtaku/memcached_sample] (len: 1)
Sending image list
Pushing repository vimtaku/memcached_sample (1 tags)
511136ea3c5a: Image already pushed, skipping 
b74728ce6435: Image already pushed, skipping 
72e10143e54a: Image already pushed, skipping 
28d8e9cef54f: Image successfully pushed 
6be17bb13216: Image successfully pushed 
1b910f3ee9b7: Image successfully pushed 
18e04c08eb9b: Image successfully pushed 
2e32ba041afa: Image successfully pushed 
1cf353d00dd8: Image successfully pushed 
242bd405025e: Image successfully pushed 
Pushing tags for rev [242bd405025e] on {https://registry-1.docker.io/v1/repositories/vimtaku/memcached_sample/tags/latest}</code></pre>
</div>

<p><br /></p>

<h3 id="section-4">出来上がりイメージ</h3>
<p><img src="http://gyazo.com/6a99a7bdffa6ce80369dad852461aacb.png" style="width:100%;" /></p>

<h2 id="section-5">所感</h2>
<p>この記事では、 docker の一番の利点だと感じている、 image を簡単に作って試す、みたいな部分は書いていない。<br />
すごい早さで image を作り出すことができるのには感動した。そこが一番の利点だと思う。<br />
あと、<a href="http://www.oreilly.co.jp/community/blog/2010/02/union-mount-uniontype-fs-part-1.html">この oreilly の資料</a>は 3回くらい読む価値はありそうだ。  </p>

<h2 id="section-6">参考文献</h2>
<p><a href="http://ja.wikipedia.org/wiki/LXC">http://ja.wikipedia.org/wiki/LXC</a><br />
<a href="http://gihyo.jp/admin/column/01/vm/2011/lxc_container">http://gihyo.jp/admin/column/01/vm/2011/lxc_container</a><br />
<a href="http://ja.wikipedia.org/wiki/Cgroups">http://ja.wikipedia.org/wiki/Cgroups</a><br />
<a href="http://www.oreilly.co.jp/community/blog/2010/02/union-mount-uniontype-fs-part-1.html">http://www.oreilly.co.jp/community/blog/2010/02/union-mount-uniontype-fs-part-1.html</a><br />
<a href="http://teppeis.hatenablog.com/entry/docker">http://teppeis.hatenablog.com/entry/docker</a><br />
<a href="http://shibayu36.hatenablog.com/entry/2013/12/30/173949">http://shibayu36.hatenablog.com/entry/2013/12/30/173949</a><br />
<a href="http://2013.8-p.info/japanese/06-22-docker.html">http://2013.8-p.info/japanese/06-22-docker.html</a>  </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[chef についてのメモ2]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/27/chef-memo-2/"/>
    <updated>2014-01-27T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/27/chef-memo-2</id>
    <content type="html"><![CDATA[
<h2 id="chef--libraries-">chef の libraries を使う場合の今のところの俺の結論</h2>

<p>以下に述べる、 1 の方法を使う。  </p>

<p>とはいえ一長一短な気がするからどっちがいいって言えない。<br />
ちなみに libraries から node はみたいよね、っていう前提。<br />
あと、自分の環境(chef-solo, v11.8.2)にもよるかも。まぁ参考程度に。<br />
もっといい方法あったら教えて下さい。<br />
(っていうか意外に chef (libraries)のドキュメントって少ない気がする..)  </p>

<h2 id="libraries-">libraries を使う方法</h2>
<ol>
  <li>class MyClass みたいなクラスを定義して、 new するときに node 渡すようにして、あとは好きに使うパターン</li>
  <li>module MyModule みたいなモジュールを定義して、extend してから、わかりやすいメソッドを呼び出して使うパターン</li>
</ol>

<h2 id="section">1. のメリット、デメリット</h2>

<h3 id="section-1">メリット</h3>
<ul>
  <li>呼びたいメソッドを MyClass.method とかけるから、コードが読みやすいのではないだろうかということ。</li>
</ul>

<h3 id="section-2">デメリット</h3>
<ul>
  <li>他のレシピからでも MyClass が使える</li>
</ul>

<h2 id="section-3">2. のメリット、デメリット</h2>

<h3 id="section-4">メリット</h3>
<ul>
  <li>名前空間を汚染しない</li>
</ul>

<h3 id="section-5">デメリット</h3>
<ul>
  <li>いちいち呼びたい recipe で extend とか書かなきゃいけない</li>
  <li>呼び出すときに method_name だけしかないからちょっと読みにくいかも、と思った。 ruby ってそういうもん？</li>
</ul>

<h2 id="section-6">以下駄文メモ</h2>

<ul>
  <li>class をつかう場合、 名前空間を切って使用すると node が見えないので不便
    <ul>
      <li>class Chef::Recipe にメソッドをはやして node を使えば見れる</li>
      <li>class Chef::Recipe::Hoge からは node はみえない
        <ul>
          <li>そんならChef::Recipe::Hoge みたいなインスタンスを new するときに node 渡して使えばいいんじゃね?</li>
          <li>まぁできんことはない</li>
        </ul>
      </li>
      <li>class Chef::Recipe にメソッド生やすのとかは Recipe が汚れるからやらない方がいい</li>
      <li>単純に class MyClass みたいなやつを new してそれを使うのが吉かも</li>
      <li>でも libraries に定義しているから他のレシピから使われる可能性があって、閉じたい人的にはアレ</li>
    </ul>
  </li>
  <li>module をつかう場合
    <ul>
      <li>extend Module名 を使えば、 node は見えるし、使う場所が限られる
        <ul>
          <li>いちいち extend するのはめんどい</li>
          <li>呼び出すとき method 名 だけになるからそれが許容できるならそれでもいいかも</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="section-7">関連記事</h2>
<p><a href="http://vimtaku.github.io/chef/2014/01/24/chef-memo/">http://vimtaku.github.io/chef/2014/01/24/chef-memo/</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一月ももう終わりそう]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/26/life-jan-last/"/>
    <updated>2014-01-26T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/26/life-jan-last</id>
    <content type="html"><![CDATA[
<h2 id="section">先週の振り返り</h2>
<p>先週は chef と格闘しっぱなしだった。<br />
まぁでも opsworks についての理解もかなり深まったし、<br />
chef の感覚はものすごくつかめたのでよかった。<br />
自分でも新しい recipe 複数かいたし。<br />
でもなんだか仕事が忙しかった気がする。<br />
あと、ブログのアウトプットも増えてきた。<br />
だれに読まれようが関係ない気持ちで書くと案外かけるもんだ。<br />
まぁ, Jekyll で書けるってのがかなり大きいんだけれども。  </p>

<p>あ、あと ruby 書くために整理したかったので .vimrc を一新した。<br />
そして今流行の homesick を使うようにした。<br />
各環境で .zshrc とか違っている感があるので、徐々に改善していく。  </p>

<h2 id="section-1">勉強途中経過</h2>

<h3 id="section-2">進んだ</h3>
<ul>
  <li>rails tutorial 6 までやった</li>
</ul>

<h2 id="section-3">読書途中経過</h2>

<h3 id="section-4">進んだ</h3>
<ul>
  <li>詳解UNIXプログラミング第6章まで読んだ</li>
  <li>プログラマの数学 4章まで読んだ</li>
  <li>パーフェクトルビー5章まで読んだ
    <ul>
      <li>手を動かしながら ver</li>
    </ul>
  </li>
</ul>

<h3 id="section-5">積んでる</h3>
<ul>
  <li>オペレーティングシステム 6章まで読んだ</li>
  <li>Webエンジニアのためのデータベース技術［実践］入門 7章まで読んだ</li>
  <li>ネットワークはなぜつながるのか?</li>
  <li>chef-solo 入門 #23 まで読んだ(どっかで手を動かしながらやる)</li>
</ul>

<h3 id="section-6">読み終えた</h3>
<ul>
  <li>(2014/1/26)マスタリングTCP/IP 入門第5版 とりあえず読み切った</li>
  <li>(2014/1/13)読む筋トレ</li>
  <li>(2014/1/8)ザ・コーチ 最高の自分に出会える「目標の達人ノート」</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[chef についてのメモ]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/24/chef-memo/"/>
    <updated>2014-01-24T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/24/chef-memo</id>
    <content type="html"><![CDATA[
<h2 id="section">概要</h2>
<p>chef について、現時点でわかっている、知っておいたら役立ちそうなメモを書いておく。
いわゆる実際ソース追えばわかるんだけど、まだソース追ってないので段階での現在わかっている挙動まとめ。  </p>

<h2 id="attribute-">attribute の読み込み順について</h2>
<ul>
  <li>attributes/default.rb が一番最初に読み込まれる</li>
  <li>attributes/hoge.rb などの、attributes ディレクトリの他のファイルが辞書順に読み込まれる</li>
  <li>node の値は各ファイルで上書きをすることができる  </li>
</ul>

<h2 id="libraries-">libraries について</h2>
<ul>
  <li>libraries/hoge.rb などに、 Chef::Recipe::Hoge などのクラスを定義して、recipe から呼び出すことができる。
    <ul>
      <li>Hoge.fuga_method として recipe から使用可能。</li>
    </ul>
  </li>
  <li>他のレシピを同時に実行するときでも、Hoge.fuga_method は使用可能。</li>
  <li>libraries/mymodule.rb などに、 module MyModule などのモジュールを定義して、 recipe から呼び出すことができる。
    <ul>
      <li>自分がイマ実行しているレシピのみでモジュールを使用したい場合は、レシピに extend MyModule して特異メソッドとしてメソッドを生やす。</li>
      <li>他のレシピでもモジュールを使用したい場合は、::Chef::Recipe.send(:include, MyModule) として Chef::Recipe クラスに include することで、my_module_method を呼び出せる。</li>
    </ul>
  </li>
</ul>

<h2 id="chef-">chef 実行時のレシピについて</h2>
<ul>
  <li>各レシピ、例えば first, second っていうレシピがあったとすると、それらは Chef::Recipe インスタンスである。
    <ul>
      <li>chef 実行時に self をみればわかる</li>
    </ul>
  </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[fog っていう gem で use_iam_profile があんまうまく行かない件]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/21/fog-iam-profile/"/>
    <updated>2014-01-21T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/21/fog-iam-profile</id>
    <content type="html"><![CDATA[
<h2 id="section">現象</h2>
<p>iam_profile を使うことで、 aws_access_key や aws_access_secret を具体的に指定しなくても、<br />
metadata な endpoint にアクセスして一時的な access_key と secret を取得できるようになっている(できたのは割と最近らしい)。<br />
それなら、iam を使いたいわけなんだけど、 fog v1.18.0 と v1.19.0 で試しても use_iam_profile がうまくいかない。  </p>

<p>呼び出しているクライアントライブラリは asset_sync v1.0.0 と elasticsearch v0.3.4 。<br />
どちらも aws_credential fetcher で credential を取得してるみたいだけど、それを使ってないようにみえた。  </p>

<h2 id="section-1">対処</h2>
<p>全部読んでないからわからないけど、俺の予想が合っていれば<br />
credential を撮ってきたものを使用していないので ここが怪しかった。  </p>

<p>lib/fog/core/service.rb</p>
<div>
  <pre><code class="bash">-options = options.merge(fetch_credentials(options))
+options = fetch_credentials(options).merge(options)</code></pre>
</div>

<p>とりあえずもっと調べなきゃよくわからない。<br />
これがうまくいっていそうなら pull req だしてみよう。  </p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[chef で opsworks のインスタンス起動時に cloudwatch の alarm を作成するためにしたこと]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/20/cloud-watch-alarm/"/>
    <updated>2014-01-20T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/20/cloud-watch-alarm</id>
    <content type="html"><![CDATA[
<h2 id="toc">TOC</h2>
<ul id="markdown-toc">
  <li><a href="#toc">TOC</a></li>
  <li><a href="#section">大まかな流れ</a></li>
  <li><a href="#iam-">1. IAM の設定</a></li>
  <li><a href="#sns-">2. SNS のトピックの作成</a></li>
  <li><a href="#cloud-watch--api--cli-">3. cloud watch の API を cli から叩いてみる</a>    <ul>
      <li><a href="#from-cli">メトリックの作成 from cli</a></li>
    </ul>
  </li>
  <li><a href="#cloud-watch-">4. cloud watch での作成確認</a></li>
  <li><a href="#chef-recipe-">5. chef recipe を書く</a></li>
  <li><a href="#opsworks--setup-">6. opsworks のレイヤー設定で、 setup ライフサイクルイベントで設定</a>    <ul>
      <li><a href="#section-1">おまけ</a>        <ul>
          <li><a href="#section-2">気をつけること要点</a></li>
          <li><a href="#section-3">標準出力から入力をし続けるからメモリに確保し続けるコマンド</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="section">大まかな流れ</h2>
<ol>
  <li>IAM の設定</li>
  <li>SNS のトピックの作成(メール送る用)</li>
  <li>cloud watch の API を cli から叩いてみる</li>
  <li>cloud watch の手動確認</li>
  <li>chef recipe を書く</li>
  <li>opsworks のレイヤー設定で、 setup ライフサイクルイベントで設定</li>
</ol>

<p>ではさっそく。  </p>

<h2 id="iam-">1. IAM の設定</h2>
<p>opsworks ではインスタンス生成時に デフォルトで Default IAM instance profile を設定できる。<br />
ここの IAM Role に権限がないと、 aws cli から操作ができないので注意する。
この記事では、IAMの設定については詳細に明記しない。  </p>

<h2 id="sns-">2. SNS のトピックの作成</h2>
<p>コマンドラインか AWS Console から、メール送る用に トピックを作成する。<br />
監視しているインスタンスの異常時にメールを受け取るため。<br />
CLI ではこちらが参考になる。<br />
<a href="http://exploreaws.doorblog.jp/archives/24701093.html">http://exploreaws.doorblog.jp/archives/24701093.html</a><br />
サブスクリプションを許可しておくと後々のチェックで捗る。<br />
ちなみにこれは、あとで alarm-actions に指定する。  </p>

<p>ここではできた topic が、仮に arn:aws:sns:ap-northeast-1:99999999:mogemoga としておく。  </p>

<h2 id="cloud-watch--api--cli-">3. cloud watch の API を cli から叩いてみる</h2>

<h3 id="from-cli">メトリックの作成 from cli</h3>

<div>
  <pre><code class="bash">aws cloudwatch put-metric-alarm
--alarm-name='disk-usage' \
             --alarm-description 'Disk usage alert' \
             --alarm-actions='arn:aws:sns:ap-northeast-1:99999999:mogemoga'   \
             --namespace  'System/Linux'  \
             --metric-name  'DiskSpaceUtilization'   \
             --dimensions='[{&quot;Name&quot;: &quot;InstanceId&quot;,&quot;Value&quot;: &quot;i-deadbeaf&quot;},{&quot;Name&quot;:&quot;Filesystem&quot;,&quot;Value&quot;: &quot;/dev/xvda1&quot;},{&quot;Name&quot;:&quot;MountPath&quot;,&quot;Value&quot;:&quot;/&quot;}]' \
             --statistic  'Average' \
             --period  '300'   \
             --unit 'Percent'
             --threshold  '50'
             --evaluation-periods  '1'
             --region 'ap-northeast-1'
             --comparison-operator 'GreaterThanOrEqualToThreshold'</code></pre>
</div>

<p>ここですんなりうまくいくかどうかが別れると思う。<br />
IAM role を使う場合は、権限が許可されていれば問題なく通ると思う。<br />
権限がない場合は、 cli の credential 設定が必要になるかもしれない。<br />
<a href="http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/SettingUp_CommandLine.html">http://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/SettingUp_CommandLine.html</a>  </p>

<h2 id="cloud-watch-">4. cloud watch での作成確認</h2>
<p>上記のコマンドで成功していれば AWS Console から cloud watch のアラームができているはずなので確認する。  </p>

<h2 id="chef-recipe-">5. chef recipe を書く</h2>

<p>あとは、上記 3 を実行する chef のレシピを書いて、 opsworks が取ってくる custom chef recipe のレポジトリに配置すればおｋ．<br />
今回は load average もとりたかったので、<br />
<a href="http://aws.amazon.com/code/8720044071969977">http://aws.amazon.com/code/8720044071969977</a><br />
のスクリプトを改変して使用することにした。<br />
ソースはこちら -&gt; <a href="https://github.com/FumihikoSHIROYAMA/cloud_watch_script.git">https://github.com/FumihikoSHIROYAMA/cloud_watch_script.git</a><br />
disk space をとったりすることができる pl なのですごく便利。  </p>

<p>下記の repository は crontab に 上記の pl (load average は別) のものを登録するものだ。<br />
<a href="https://github.com/alexism/cloudwatch_monitoring">https://github.com/alexism/cloudwatch_monitoring</a>  </p>

<p>これをフォークして、 load average とれる cron を作る機能と、 アラーム登録する奴を書いた。<br />
<a href="https://github.com/vimtaku/cloudwatch_monitoring.git">https://github.com/vimtaku/cloudwatch_monitoring.git</a><br />
chef 力低めで申し訳なので、アドバイス、pull req など大歓迎。  </p>

<h2 id="opsworks--setup-">6. opsworks のレイヤー設定で、 setup ライフサイクルイベントで設定</h2>
<p>これはもう、 opsworks に慣れているひとなら問題無いと思う。<br />
5 で作ったものがうまくいっていれば(というか試すときに deploy かどっかで試すと思うんだけど)<br />
それを setup に移動してやるだけだ。  </p>

<h3 id="section-1">おまけ</h3>

<h4 id="section-2">気をつけること要点</h4>
<ul>
  <li>IAM Role に権限がない場合があるので気をつける
    <ul>
      <li>参考
        <ul>
          <li><a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/UsingIAM.html">http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/UsingIAM.html</a></li>
          <li><a href="http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-CreateVolume.html">http://docs.aws.amazon.com/AWSEC2/latest/APIReference/ApiReference-query-CreateVolume.html</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>opsworks では chef の data_bags が使えないのを頭に入れておく
    <ul>
      <li>自分はあとから気づいたパターン
        <ul>
          <li>詳細は <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook-chef11.html">http://docs.aws.amazon.com/opsworks/latest/userguide/workingcookbook-chef11.html</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>mon-put-metric-alarm の代わりに aws cloudwatch put-metric-aaerm を使用する
    <ul>
      <li>role の設定ができていても credential エラーとかいっぱい言われるため。</li>
    </ul>
  </li>
  <li>alert と alarm が似ているので alerm ってタイポに気をつける</li>
</ul>

<h4 id="section-3">標準出力から入力をし続けるからメモリに確保し続けるコマンド</h4>
<div>
  <pre><code class="bash">/dev/null &lt; $(yes)
cat - &lt; $(yes)</code></pre>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[俺なりの自炊セットをそろえた]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/19/jisui-best-practice/"/>
    <updated>2014-01-19T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/19/jisui-best-practice</id>
    <content type="html"><![CDATA[
<h2 id="section">背景</h2>
<p>覚悟を決めたので自炊セットを買うことにした。<br />
電子書籍は最近出てくることが多くなったとはいえ、<br />
すべてが電子書籍で販売されている訳ではないからだ。<br />
Nexus7 を存分に生かすために買った自炊セットの<br />
俺なりのベストプラクティスをここに記載する。  </p>

<p>とはいえ、家にある本の数は100冊程度なので、<br />
もしかしたら裁断サービスのほうが安く上がるかもしれないが<br />
安値で自炊セットをそろえれば、家の雑多な書類とかも処理できるし<br />
楽なのでそろえることにした。  </p>

<p>とにかく安くそろえることを前提とした。</p>

<h2 id="section-1">俺なりの結論</h2>
<ul>
  <li>スキャナ
    <ul>
      <li>image FORMULA DR-C125</li>
    </ul>
  </li>
  <li>裁断機
    <ul>
      <li>カール事務器 ディスクカッターA4サイズ対応 丸刃40枚裁断(2往復) ブラック DC-210N</li>
    </ul>
  </li>
</ul>

<p>計、約3万円也。。</p>

<h2 id="section-2">スキャナの選定</h2>
<p>スキャナは実際すごくまよったが、とにかく安くそろえたかったので、<br />
ScanSnap1500 の中古か image FORMULA DR-C125 にしようと思っていた。<br />
結構比較記事があるので、ググってもらえばわかると思うけど、<br />
SS1500は重送とかが結構おこるといわれていたのと、Amazon のレビューの評判が<br />
そこそこよさげだったので、 image FORMULA DR-C125 にした。<br />
安さの観点から、比較対象として SS1300 とか、ハンディスキャナとかがあったけど<br />
SS1500 とのスキャンスピード比較動画が結構えげつない差だったので SS1300 はやめた。<br />
ちなみに、 SS1500 よりも DR-C125 のほうが早い感じらしい。<br />
ScanSnap1500 マジ良いみたいな話で、実際に使ったこと無いから比較できないけど、<br />
DR-C125 はとても良いものだった。ちなみにヤフオクで 約2万円で中古を買った。<br />
なんていうか、Mac 用のドライバを普通にインストールして、<br />
すぐにスキャンできた。OCR も効いている。<br />
新品も Amazon で2.7万くらいなので、新品でも良いかもしれない。<br />
アフィは張らない。  </p>

<h2 id="section-3">裁断機の選定</h2>
<p>ローラーカッター(1000円)とカッターマット、定規で行けるかと思っていたんだけど、<br />
分厚い本とか、マジ無理です。絶対無理。<br />
いや、無理ではない、正確には。<br />
でも、自炊とか効率的なことを考える人がやることではない。<br />
カッターでもいい人は、新書とかばかりのひと。<br />
それなら余裕。技術書はたぶん相当に厳しい。<br />
なので、ちょうど今さっき、評判が割と良い DC-210N の裁断機を買った。<br />
約1万円也。<br />
どうなるかわからないが、絶対手動よりはマシだと思う。<br />
それくらい、非現実的だと思う。行けると思っていた俺浅はか。  </p>

<h2 id="section-4">あとは読むだけ</h2>
<p>自炊しっぱなしで読まないみたいなのがありそうだけど、必ず読むよ。<br />
学習し続けることは、尊い。<br />
たゆまぬ努力を続けよう。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[asset_sync]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/14/asset-sync/"/>
    <updated>2014-01-14T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/14/asset-sync</id>
    <content type="html"><![CDATA[
<h2 id="rails--asset-pipeline--s3-opsworks">rails で asset pipeline を使って s3 に上げる手順について(opsworks使用)</h2>

<h2 id="url">参考URL</h2>
<p>こちらを参考にした。
<a href="http://d.hatena.ne.jp/lettas0726/20130320/1363773153">http://d.hatena.ne.jp/lettas0726/20130320/1363773153</a></p>

<h4 id="gemfile">Gemfile</h4>
<div>
  <pre><code class="ruby">gem 'uglifier', '&gt;= 1.3.0'
gem 'asset_sync'</code></pre>
</div>

<p>を追記。</p>

<h4 id="deploybeforemigraterb">deploy/before_migrate.rb</h4>

<div>
  <pre><code class="ruby">template &quot;#{release_path}/config/asset_sync.yml&quot; do
  mode &quot;0644&quot;
  source &quot;asset_sync.yml.erb&quot;
end

bash &quot;precompile_assets&quot; do
  user &quot;deploy&quot;
  cwd release_path
  code 'bundle exec rake assets:precompile RAILS_ENV=production'
end</code></pre>
</div>

<p>今回は、 before_migrate で呼ぶことにする。<br />
chef-solo で呼ばれるので resource が使える模様。<br />
カスタム chef リポジトリに asset_sync.yml の template を用意しておく。<br />
template は asset_sync.yml.erb としておいておく感じ。</p>

<h4 id="configenvironmentsproductionrb">config/environments/production.rb</h4>
<p>hoge.example.com のバケットとしたとき、以下のように追記。</p>

<div>
  <pre><code class="ruby">config.action_controller.asset_host = '//s3-ap-northeast-1.amazonaws.com/hoge.example.com'
config.assets.initialize_on_precompile = true</code></pre>
</div>

<h2 id="existingremotefiles-">existing_remote_files オプションについて</h2>
<p>アセットパイプラインでは、ファイルにおそらく md5 の hash 値がついているのを生成する。<br />
ここで複数の rails インスタンスが非同期(もしくは片方のみ)なので<br />
existing_remote_files: ‘delete’ として<br />
precompile を実行するともともと参照していたファイルが消えてしまうので、<br />
config/asset_sync.yml の中の existing_remote_files を keep にする。<br />
(しかし、ゴミはのこる。対処については要検討。  </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[読む筋トレを読んだ]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/13/yomu-kintore-memo/"/>
    <updated>2014-01-13T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/13/yomu-kintore-memo</id>
    <content type="html"><![CDATA[
<h2 id="section">所感</h2>
<p>筋トレのモチベーションが上がったというよりは、なぜ筋トレをするのか考えることにつながった。<br />
自分はダイエットで成功体験があったり、筋トレは結構日常に組み込んでやってたときがあったけど、<br />
仕事で一気に忙しくなったときにその習慣がなくなってしまった。<br />
それをまたやる気にしてくれそうな雰囲気である。<br />
この本では、ボディデザインという概念を提唱している。<br />
ダイエットという引き算の発想から、筋トレをすることで自然に脂肪を減らすというものだ。<br />
この考えには多いに賛成だが、実際のところ好きなものを食べて筋肉バキバキとかはちょっと無理がある。<br />
食べ過ぎた次の日にはいっぱい筋トレして解消するみたいな考え方は確かに素晴らしいけどなぁ。<br />
あと自分を知るということについてもすごく参考にはなる。<br />
こと自分に至っては, 本当にお酒を飲むことがマイナスでしかない。<br />
お酒を飲むとすごく食欲が増してしまってドカ食いしてしまうし。<br />
なので無理せず減らすとかを考えるべきだと思う。  </p>

<p>五分でいいから筋トレを日常に組み込むというのはすごく励みになる。<br />
0じゃなく、多くなくてよいから1を繰り返せば 100 になるという発想。<br />
これはかなり良い発想かもしれない。</p>

<h2 id="section-1">自分にとっての筋トレの目的</h2>
<p>はっきり言って映画トランスポーターに出てくるジェイソンステイサムのようになりたい。<br />
すごく憧れる。俺の中で世界一かっこいいハゲ。<br />
自分のポリシーをはっきりともちつつ、「立っているだけで笑わせる」と言い切る笑いへの価値観。<br />
パーフェクトだ。  </p>

<p>この如何ともしがたい理想との乖離を埋めるべく、ジムで筋トレをしようと思う。  </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[1月一周目]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/13/life-log/"/>
    <updated>2014-01-13T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/13/life-log</id>
    <content type="html"><![CDATA[
<h2 id="section">先週の振り返り</h2>
<p>先週は年明け一発目って感じだったが、モチベーションが自分の中で勝手に上がってきててよかった。<br />
目標に関する本を読みおえて、改めて立ててみると意外に行けそうな気がした。<br />
引き続き aws, chef などを触っているが、理解がかなり進んだように感じる。<br />
chef のレシピを一から20分くらいで作れるようになっていたのは成長を感じた。<br />
引き続きがんばる。<br />
Nexus7 はすごく良い。  </p>

<h2 id="section-1">冬休み振り返り</h2>
<p>今思い出したけど、北海道にかえった冬休み中にそこそこ vagrant を触っていたから理解が進んだんだった。<br />
rails tutorial を倒すってのはできなかったけど、現在もりもり進行中である。  </p>

<h2 id="section-2">雑言</h2>
<p>作ろうと思ってたやつあった<br />
<a href="https://github.com/mattn/vim-textobj-url">https://github.com/mattn/vim-textobj-url</a></p>

<h2 id="section-3">読書途中経過</h2>

<h3 id="section-4">進んだ</h3>
<ul>
  <li>マスタリングTCP/IP 入門第5版 6章まで読んだ</li>
  <li>オペレーティングシステム 6章まで読んだ</li>
  <li>プログラマの数学 3章まで読んだ</li>
</ul>

<h3 id="section-5">積んでる</h3>
<ul>
  <li>詳解UNIXプログラミング第5章まで読んだ</li>
  <li>パーフェクトルビー5章まで読んだ</li>
  <li>Webエンジニアのためのデータベース技術［実践］入門 7章まで読んだ</li>
  <li>ネットワークはなぜつながるのか?</li>
  <li>chef-solo 入門 #23 まで読んだ(どっかで手を動かしながらやる)</li>
</ul>

<h3 id="section-6">読み終えた</h3>
<ul>
  <li>ザ・コーチ 最高の自分に出会える「目標の達人ノート」</li>
  <li>読む筋トレ</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[elasticsearch_ebs]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/08/z_elasticsearch-ebs/"/>
    <updated>2014-01-08T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/08/z_elasticsearch-ebs</id>
    <content type="html"><![CDATA[
<h1 id="opsworks--elasticsearch-">opsworks と elasticsearch についてのメモ</h1>

<h2 id="elasticsearch--memo">elasticsearch についての memo</h2>
<ul>
  <li>クラスタリングした時に master-slave みたいになるのか？
    <ul>
      <li>ならない。すべてがマスタになる模様</li>
      <li>複数台立てておいて、片方落としておいて、立っている方にデータPUT して落としておいた方を立ててGETできる</li>
    </ul>
  </li>
  <li>elastic search s3 gateway はパフォーマンスの問題で deprecated になっている模様
    <ul>
      <li>なので EBS でやることになる。</li>
    </ul>
  </li>
  <li>chef の recipe を見ると、設定しておけば ebs を自動で作ってマウントまでしてくれる感じになっている
    <ul>
      <li>elasticsearch::ebs, elasticsearch::data のレシピを実行すれば良い感じ。
        <ul>
          <li>opsworks では, layers に elasticsearch::ebs, elasticsearch::data の順で登録すればおｋ</li>
          <li>README に書いてある通りに設定が必要。具体的には data_bags/elasticsearch/data.json と aws の認証周りの設定が必要</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>各アベイラビリティゾーンに分散しておいておいて、 internal loadbalancer に紐付ければ、片方が死んでも大丈夫</li>
  <li>災害時の復旧については、たぶん snapshot からの復旧に加えて、 index の再作成(upsert なAPI 叩きまくる) が必要</li>
  <li>discovery については aws-instance プラグインみたいなのがあって、api 叩いてリスト取得してきている。</li>
</ul>

<h2 id="elasticsearch--memo2">elasticsearch についての memo2</h2>
<ul>
  <li>elasticsearch って aws のサービス名かと思ってたけど、別にそういうわけじゃない</li>
</ul>

<h2 id="elasticsearch--memo3">elasticsearch についての memo3</h2>
<p>opsworks のレイヤーで、internal LB をひもづけることはできると思うけど、<br />
新しく作った elasticsearch node のインデックス作成とかしている時に紐づくとまずいので<br />
いったん手動でやるようにする。(たぶんELBの死活監視を工夫すればうまいこと行ける)  </p>

<h2 id="opsworks--chef-">opsworks の chef で役立つコマンド例</h2>

<div>
  <pre><code class="bash">## setup サイクルを retry
opsworks-cli-agent run_command setup

## custom.json を dump
opsworks-cli-agent get_json &gt; hoge.json

## ログをみる
opsworks-cli-agent show_log

## hoge.json を指定すれば、楽にもう一度ライフサイクルを指定できる
&quot;/opt/aws/opsworks/current/bin/chef-solo&quot; -j &quot;hoge.json&quot; -c &quot;/opt/aws/opsworks/current/conf/solo.rb&quot; -L &quot;/var/lib/aws/opsworks/chef/2014-01-09-05-28-54-01.log&quot; &gt; &quot;/var/lib/aws/opsworks/chef/2014-01-09-05-28-54-01.log.out&quot; 2&gt;&amp;1


### 役に立つディレクトリ

## opsworks の chef-solo が走るときにログが出たり、走るときの json が出たりする
/var/lib/aws/opsworks

## opsworks の chef-solo のクックブックとかがこのへんにある。
/opt/aws/opsworks</code></pre>
</div>

<h2 id="useiamprofile-">use_iam_profile がうまく行かない件</h2>
<p>gem の fog を使うところで use_iam_profile =&gt; true で渡しても全然うまく動かない問題があって、<br />
ライブラリのバグかもと思ったけどなんか違うっぽくて、時間がなかったので custom.json で大人しく accesskey とかを指定した。<br />
おそらく _request の時に credential の作成をしているんだけど、そこでミスっているんじゃないかなぁという予想。</p>

<h2 id="section">参考資料というか調べてく時に必要だったこと。</h2>
<ul>
  <li><a href="https://github.com/elasticsearch/elasticsearch/issues/2458">https://github.com/elasticsearch/elasticsearch/issues/2458</a></li>
  <li><a href="http://www.elasticsearch.org/tutorials/elasticsearch-on-ec2/">http://www.elasticsearch.org/tutorials/elasticsearch-on-ec2/</a></li>
  <li><a href="http://www.smokeymonkey.net/2013/10/elasticsearchcluster.html">http://www.smokeymonkey.net/2013/10/elasticsearchcluster.html</a></li>
  <li><a href="http://docs.aws.amazon.com/opsworks/latest/userguide/troubleshoot-debug-cli.html">http://docs.aws.amazon.com/opsworks/latest/userguide/troubleshoot-debug-cli.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ザ・コーチって本を読んだ]]></title>
    <link href="http://vimtaku.github.io/blog/2014/01/08/memo_the_coach/"/>
    <updated>2014-01-08T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2014/01/08/memo_the_coach</id>
    <content type="html"><![CDATA[
<h2 id="section">所感</h2>
<p>読み物形式の、ただの自己啓発本。<br />
自己啓発本の部類は7つの習慣とか読んどけば多分良くて<br />
ナポレオンヒルのやつとかも読んでたので<br />
内容はあんまり大差ない気がする。<br />
一応まとめたので書いておく。<br />
内容がものすごく自己啓発本だから実際に自分で文字を打つと<br />
すごい感じする。<br />
こういうのは読むとすごく大事だと思うんだけど、<br />
いざ毎日見る、みたいな仕組みづくりに挫折する場合がおおい。<br />
どこか生活の一部に組み込めばいいかもしれない。<br />
たとえばアラームとか。</p>

<h3 id="section-1">達人になるための3つの輪</h3>
<ul>
  <li>知識</li>
  <li>道具</li>
  <li>能力</li>
</ul>

<h3 id="section-2">ことばについて</h3>
<ul>
  <li>目標
    <ul>
      <li>目的を達成するためにもうけた目当て</li>
    </ul>
  </li>
  <li>目的
    <ul>
      <li>成し遂げようと目指す事柄</li>
    </ul>
  </li>
  <li>ゴール
    <ul>
      <li>目的のための最終的な目印</li>
    </ul>
  </li>
  <li>夢
    <ul>
      <li>将来自分が実現させたいと心の中に思い描いている願い</li>
    </ul>
  </li>
  <li>ビジョン
    <ul>
      <li>将来あるべき姿を描いたもの</li>
    </ul>
  </li>
</ul>

<h3 id="section-3">ドリームツリー</h3>

<blockquote><p>目    的<br />   |        |        |<br />  ゴール   ゴール    ゴール<br />|    |      |   |     |    |<br />目標 目標  目標 目標  目標  目標&#8230;</p></blockquote>

<h3 id="section-4">上記の5つの項目を設定することで良いこと</h3>
<ul>
  <li>共感者や協力者が現れる</li>
  <li>
    <p>同じ価値観を持った仲間が増える</p>
  </li>
  <li>目標に向かって努力することで人は成長する</li>
  <li>目標に向かって努力すれば、たとえそれがかなえられなかったとしても、人は精神的に強くなる</li>
  <li>誰かと同じ目標に向かってがんばることで、その後の人生の宝になる絆が生まれる</li>
  <li>目標を達成することで、達成感を味わえる</li>
  <li>ゴールを目指すことで、どんな人間に成長したかが重要</li>
</ul>

<h3 id="section-5">ベネフィットとは</h3>
<ul>
  <li>その道のりで、多くの共感者や協力者と出会い、さらに大きなことを成せる</li>
  <li>精神的に強くなり、更なる大きな決断の時に必要な勇気を手にする</li>
  <li>人間的に成長する</li>
  <li>人と人との絆が生まれ、人生の宝を得る</li>
  <li>人生が、ワクワク感やドキドキ感にあふれた、感情豊かで感動的なものになる</li>
  <li>知識, 選択力, 決断力, 集中力が増える</li>
  <li>知識・能力・道具が増えて価値ある人になる</li>
  <li>次の成功のための糧を手にする</li>
  <li>どん底にいるとき、詩人になり、魅力的な人物になる</li>
  <li>可能性の扉が開き、想像もしなかった未来の自分に会える</li>
  <li>精神的な視点が高くなり、人生で見る景色が変わる</li>
  <li>人生を存分に堪能できる</li>
</ul>

<h3 id="section-6">夢やゴールや目標の作成を妨げるブレーキとは</h3>
<ul>
  <li>方向を誤った目的</li>
  <li>他者からの批判や避難、成長期に味わった他者との比較等による学習性無力感</li>
  <li>夢やゴールや目標に対する無知</li>
  <li>結果による人格否定</li>
  <li>弱みを克服することばかり強いられる経験</li>
  <li>変化に対する恐れ</li>
  <li>選択と決断に対する恐れ</li>
</ul>

<h3 id="section-7">その他</h3>
<ul>
  <li>目的はゆるぎなく、ゴールを手にする方法は無限にあると尻、目標は柔軟に対応する</li>
  <li>ゴール達成を構成している要素を分解して、そこに期日と量と基準を盛り込んで旗(</li>
  <li>ゴールのための行動計画を目標とすると、ノルマかして意欲が下がる</li>
  <li>ゴールを設定したら、ゴールツリーを書いて、そのゴール達成を構成する知識と能力とツールに分解する</li>
  <li>行動を設計する</li>
  <li>目標には通過する状態を書く</li>
  <li>ゴールは目指すが、それだけにとらわれて自分を見失わない</li>
  <li>目標の主語を私にして、いつ、何が、どうなるという表現にする
    <ul>
      <li>何々するために、何何の状態になっている</li>
    </ul>
  </li>
  <li>目標はやるべきことではなく、ゴールまでの通過点や指標とする</li>
  <li>目標を設定したら、そのプロセスで「開かれた質問」を自分自身に問いかけて、思考力や解決力を鍛える
    <ul>
      <li>どうしたらうまくできるだろうか?</li>
      <li>効率的にするにはどうすればいいだろうか？</li>
      <li>今日この目標にたいして何をしただろうか?など。</li>
    </ul>
  </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[chef_for_me]]></title>
    <link href="http://vimtaku.github.io/blog/2013/12/27/z_chef-for-me/"/>
    <updated>2013-12-27T00:00:00+09:00</updated>
    <id>http://vimtaku.github.io/blog/2013/12/27/z_chef-for-me</id>
    <content type="html"><![CDATA[
<h1 id="chef-solo-vagrant-">chef-solo, vagrant に慣れるためにそれっぽいチュートリアルをやる</h1>

<h2 id="tutorial-">tutorial っぽいのがあったのでやってみる</h2>
<p><a href="http://vialstudios.com/guide-authoring-cookbooks.html">http://vialstudios.com/guide-authoring-cookbooks.html</a></p>

<h2 id="chef-chef-solo-">chef, chef-solo について</h2>
<p>ここが詳しい。
<a href="http://knowledge.sakura.ad.jp/tech/867/">http://knowledg.sakura.ad.jp/tech/867/</a></p>

<h2 id="start">start</h2>

<p>基本的に自分のメモなのであんまり参考にならないと思うけど残しておく。  </p>

<ul>
  <li>git install
    <ul>
      <li>すでにあったので省略</li>
    </ul>
  </li>
  <li>Install rbenv and ruby-build
    <ul>
      <li>すでにあったので省略</li>
    </ul>
  </li>
  <li>Install Ruby
    <ul>
      <li>すでにあったので省略</li>
    </ul>
  </li>
  <li>Install Berkshelf
    <ul>
      <li>すでにあったので省略</li>
    </ul>
  </li>
  <li>foodcritic を入れる。</li>
</ul>

<div>
  <pre><code class="bash">$ gem install foodcritic</code></pre>
</div>

<ul>
  <li>Install VirtualBox
    <ul>
      <li>すでにあったので省略</li>
    </ul>
  </li>
  <li>Install Vagrant
    <ul>
      <li>すでにあったので省略</li>
    </ul>
  </li>
  <li>Creating the Cookbook</li>
</ul>

<div>
  <pre><code class="bash">/Users/vimtaku/vm/myface% berks cookbook myface --foodcritic
      create  myface/files/default
      create  myface/templates/default
      create  myface/attributes
      create  myface/definitions
      create  myface/libraries
      create  myface/providers
      create  myface/recipes
      create  myface/resources
      create  myface/recipes/default.rb
      create  myface/metadata.rb
      create  myface/LICENSE
      create  myface/README.md
      create  myface/Berksfile
      create  myface/Thorfile
      create  myface/chefignore
      create  myface/.gitignore
         run  git init from &quot;./myface&quot;
      create  myface/Gemfile
      create  myface/Vagrantfile</code></pre>
</div>

<p>クックブックのスケルトンテンプレートを、 myface っていう名前で作成した。</p>

<ul>
  <li>Prepare your virtual environment
    <ul>
      <li>vendor/bundle にインストールする設定をやってなかったらやっておいたほうが良いかも
        <ul>
          <li><a href="http://qiita.com/toshiwo/items/4e7c82852f3e14bf5a1d">http://qiita.com/toshiwo/items/4e7c82852f3e14bf5a1d</a></li>
        </ul>
      </li>
      <li>bundle install</li>
    </ul>
  </li>
  <li>Starting your virtual machine
    <ul>
      <li>とりあえず言われたとおりにやってみろってことなのでやってみる</li>
    </ul>
  </li>
</ul>

<div>
  <pre><code class="bash">/Users/vimtaku/vm/myface/myface% bundle exec vagrant up
   ringing machine 'default' up with 'virtualbox' provider...
   [default] Box 'Berkshelf-CentOS-6.3-x86_64-minimal' was not found. Fetching box from specified URL for
   the provider 'virtualbox'. Note that if the URL does not have
   a box for this provider, you should interrupt Vagrant now and add
   the box yourself. Otherwise Vagrant will attempt to download the
   full box prior to discovering this error.
   Downloading or copying the box...
   Progress: 22% (Rate: 1045k/s, Estimated time remaining: 0:03:45)load: 1.56  cmd: curl 27613 waiting 0.84u 1.48s
   Progress: 50% (Rate: 1068k/s, Estimated time remaining: 0:02:03)load: 1.47  cmd: curl 27613 waiting 1.76u 3.18s
   Progress: 51% (Rate: 1147k/s, Estimated time remaining: 0:02:01)^U
   Progress: 85% (Rate: 1061k/s, Estimated time remaining: 0:00:38)load: 1.27  cmd: curl 27613 waiting 2.72u 4.99s
   Extracting box...te: 2251k/s, Estimated time remaining: 0:00:01)j
   Successfully added box 'Berkshelf-CentOS-6.3-x86_64-minimal' with provider 'virtualbox'!
   There are errors in the configuration of this machine. Please fix
   the following errors and try again:
   
   SSH:
   * The following settings shouldn't exist: max_tries, timeout</code></pre>
</div>

<ul>
  <li>エラー。 ssh
    <ul>
      <li>https://github.com/berkshelf/berkshelf/pull/856</li>
      <li>vagrant バージョンの違いによるものっぽい、削除して try</li>
    </ul>
  </li>
</ul>

<div>
  <pre><code class="bash">/Users/vimtaku/vm/myface/myface% bundle exec vagrant up
Bringing machine 'default' up with 'virtualbox' provider...
[default] Importing base box 'Berkshelf-CentOS-6.3-x86_64-minimal'...
[default] Matching MAC address for NAT networking...
[default] Setting the name of the VM...
[default] Clearing any previously set forwarded ports...
[Berkshelf] This version of the Berkshelf plugin has not been fully tested on this version of Vagrant.
[Berkshelf] You should check for a newer version of vagrant-berkshelf.
[Berkshelf] If you encounter any errors with this version, please report them at https://github.com/RiotGames/vagrant-berkshelf/issues
[Berkshelf] You can also join the discussion in #berkshelf on Freenode.
[Berkshelf] Updating Vagrant's berkshelf: '/Users/vimtaku/.berkshelf/default/vagrant/berkshelf-20131227-27600-dzfcmn-default'
[Berkshelf] Using myface (0.1.0) from metadata
[default] Creating shared folders metadata...
[default] Clearing any previously set network interfaces...
[default] Preparing network interfaces based on configuration...
[default] Forwarding ports...
[default] -- 22 =&gt; 2222 (adapter 1)
[default] Booting VM...
[default] Waiting for machine to boot. This may take a few minutes...
[default] Machine booted and ready!
[default] Setting hostname...
[default] Configuring and enabling network interfaces...
[default] Mounting shared folders...
[default] -- /vagrant
[default] -- /tmp/vagrant-chef-1/chef-solo-1/cookbooks
[default] Running provisioner: chef_solo...
Generating chef JSON and uploading...
Running chef-solo...
[2013-12-27T09:05:00+00:00] INFO: *** Chef 10.14.2 ***
[2013-12-27T09:05:01+00:00] INFO: Setting the run_list to [&quot;recipe[myface::default]&quot;] from JSON
[2013-12-27T09:05:01+00:00] INFO: Run List is [recipe[myface::default]]
[2013-12-27T09:05:01+00:00] INFO: Run List expands to [myface::default]
[2013-12-27T09:05:01+00:00] INFO: Starting Chef Run for myface-berkshelf
[2013-12-27T09:05:01+00:00] INFO: Running start handlers
[2013-12-27T09:05:01+00:00] INFO: Start handlers complete.
[2013-12-27T09:05:01+00:00] INFO: Chef Run complete in 0.017946119 seconds
[2013-12-27T09:05:01+00:00] INFO: Running report handlers
[2013-12-27T09:05:01+00:00] INFO: Report handlers complete</code></pre>
</div>

<ul>
  <li>実行されているのは Vagrantfile の中に含まれていた run_list のところのリストだった</li>
  <li>cent os とか書いているところは自分の好きな感じで設定できるよとのこと</li>
  <li>
    <p>このへんは知ってるけど不安定とかになったら vagrant destroy とかで消せるよとのこと</p>
  </li>
  <li>Deploying with Artifact Deploy
    <ul>
      <li>myface っていうスーパークールな sns アプリ作ってやろうぜとのこと
        <ul>
          <li>Artifact Deploy は LWRP を deploy するためのもの!
            <ul>
              <li>LWRP はこちらを参照 -&gt; <a href="http://sssslide.com/speakerdeck.com/kentaro/chef-lwrp">http://sssslide.com/speakerdeck.com/kentaro/chef-lwrp</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>vim で編集. </li>
    </ul>
  </li>
</ul>
<div>
  <pre><code class="bash">/Users/vimtaku/vm/myface/myface% vim recipes/default.rb

artifact_deploy &quot;myface&quot; do
  version &quot;1.0.0&quot;
  artifact_location &quot;http://dl.dropbox.com/u/31081437/myface-1.0.0.tar.gz&quot;
  deploy_to &quot;/srv/myface&quot;
  owner &quot;myface&quot;
  group &quot;myface&quot;
  action :deploy
end</code></pre>
</div>

<ul>
  <li>provision command でもう一回 chef の provision を実行する。</li>
  <li>berkshelf vagrant plugin の 魔法によって依存関係を勝手に解決してくれる!</li>
</ul>

<div>
  <pre><code class="bash">[Berkshelf] This version of the Berkshelf plugin has not been fully tested on this version of Vagrant.
[Berkshelf] You should check for a newer version of vagrant-berkshelf.
[Berkshelf] If you encounter any errors with this version, please report them at https://github.com/RiotGames/vagrant-berkshelf/issues
[Berkshelf] You can also join the discussion in #berkshelf on Freenode.
[Berkshelf] Updating Vagrant's berkshelf: '/Users/vimtaku/.berkshelf/default/vagrant/berkshelf-20131227-27600-dzfcmn-default'
[Berkshelf] Using myface (0.1.0)
[default] Running provisioner: chef_solo...
Generating chef JSON and uploading...
Running chef-solo...
[2013-12-27T09:36:54+00:00] INFO: *** Chef 10.14.2 ***
[2013-12-27T09:36:54+00:00] INFO: Setting the run_list to [&quot;recipe[myface::default]&quot;] from JSON
[2013-12-27T09:36:54+00:00] INFO: Run List is [recipe[myface::default]]
[2013-12-27T09:36:54+00:00] INFO: Run List expands to [myface::default]
[2013-12-27T09:36:54+00:00] INFO: Starting Chef Run for myface-berkshelf
[2013-12-27T09:36:54+00:00] INFO: Running start handlers
[2013-12-27T09:36:54+00:00] INFO: Start handlers complete.

================================================================================
Recipe Compile Error in /tmp/vagrant-chef-1/chef-solo-1/cookbooks/myface/recipes/default.rb
================================================================================

NameError
---------
Cannot find a resource for artifact_deploy on centos version 6.3

Cookbook Trace:
---------------
  /tmp/vagrant-chef-1/chef-solo-1/cookbooks/myface/recipes/default.rb:9:in `from_file'

Relevant File Content:
----------------------
/tmp/vagrant-chef-1/chef-solo-1/cookbooks/myface/recipes/default.rb:

  1:  #
  2:  # Cookbook Name:: myface
  3:  # Recipe:: default
  4:  #
  5:  # Copyright (C) 2013 YOUR_NAME
  6:  # 
  7:  # All rights reserved - Do Not Redistribute
  8:  
  9:  artifact_deploy &quot;myface&quot; do

[2013-12-27T09:36:55+00:00] ERROR: Running exception handlers
[2013-12-27T09:36:55+00:00] ERROR: Exception handlers complete
[2013-12-27T09:36:55+00:00] FATAL: Stacktrace dumped to /var/chef/cache/chef-stacktrace.out
[2013-12-27T09:36:55+00:00] FATAL: NameError: Cannot find a resource for artifact_deploy on centos version 6.3</code></pre>
</div>

<ul>
  <li>期待通りにエラッた
    <ul>
      <li>俺らは全然 artifact_deploy はいらない</li>
      <li>chef client が必要としているだけ</li>
      <li>俺らは LWRP が必要だっていうのを 俺らの cookbook に教えていないから教えてやる</li>
    </ul>
  </li>
  <li>Working with cookbook metadata
    <ul>
      <li>metadata.rb に教えてやる必要がある。
        <ul>
          <li>このファイルは結構初心者が見落としがちなんだけど結構大事なんだぜ</li>
          <li>metadata.rb は Rubygems で言う gemspec みたいなやつで依存関係を記述する奴で
            <ul>
              <li>name attribute で名前とか</li>
              <li>version attribute でバージョンとか</li>
              <li>depends 定義で 依存する cookbooks の記述とか</li>
              <li>conflict 定義で conflict する奴とか</li>
              <li>maintainer attribute で メンテナとか</li>
              <li>maintainer email とか</li>
              <li>license 情報 とか</li>
              <li>long_description を使って description とか
をかける!</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>全部の属性は必要ない</li>
      <li>けど attribute を空にするのはやめておけとのこと</li>
    </ul>
  </li>
  <li>
    <p>追記してbundle exec vagrant provision を実行</p>
  </li>
  <li>
    <p>ユーザ追記とかして</p>
  </li>
  <li>Using Berkshelf to gather dependencies</li>
  <li>どっから dependencies を解決しているのか</li>
  <li>metadata.rb をみていろいろやる</li>
  <li>
    <p>capistrano っぽいディレクトリ構成で deploy</p>
  </li>
  <li>Refactoring into attributes
    <ul>
      <li>attributes/default.rb に記入</li>
    </ul>
  </li>
</ul>
<div>
  <pre><code class="bash">default[:myface][:user] = &quot;myface&quot;
default[:myface][:group] = &quot;myface&quot;</code></pre>
</div>

<div>
  <pre><code class="bash">group &quot;#{node['myface']['group']}&quot;

user &quot;#{node['myface']['group']}&quot; do
  group &quot;#{node['myface']['group']}&quot;
  system true
  shell &quot;/bin/bash&quot;
end

artifact_deploy &quot;#{node['myface']['group']}&quot; do
  version &quot;1.0.0&quot;
  artifact_location &quot;/tmp/myface-1.0.0.tar.gz&quot;
  deploy_to &quot;/srv/myface&quot;
  owner &quot;#{node['myface']['user']}&quot;
  group &quot;#{node['myface']['group']}&quot;
  action :deploy
end</code></pre>
</div>

<ul>
  <li>artifact_location に /tmp 指定してるのは回線事情があって wget したやつをおいておいた.</li>
  <li>
    <p>うまく行った。書き方をちゃんとしないと validation で引っかかるので注意。</p>
  </li>
  <li>Idempotent recipes
    <ul>
      <li>レシピの冪とう性について書かれている</li>
      <li>not_if とかないと</li>
    </ul>
  </li>
  <li>Configuring the application server
    <ul>
      <li>depends “tomcat”, “~&gt; 0.11.0” を metadata.rb に追加する</li>
      <li>include_recipe “tomcat” を recipes/default.rb に追加する</li>
      <li>provision</li>
    </ul>
  </li>
  <li>include_recipe versus a Role with a run_list
    <ul>
      <li>スパイダーマンより、 大いなる力には、大いなる責任が伴う</li>
      <li>ポートフォワーディングの設定
        <ul>
          <li>config.vm.network :forwarded_port, guest: 8080, host: 9090</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Configuring Tomcat users
    <ul>
      <li>したがってやったらできた。</li>
      <li>/myapp はなぜか動かない</li>
      <li>まぁでもとりあえず受けれるところまで行ければおkなのでここまでとする</li>
    </ul>
  </li>
  <li>その下は
    <ul>
      <li>もっと attribute で可変にするところとか</li>
      <li>database の LWRP を使う例とかi
 が書いてある</li>
    </ul>
  </li>
  <li>これが便利</li>
</ul>

<div>
  <pre><code class="bash">require 'json'

file &quot;/tmp/dna.json&quot; do
  content JSON.pretty_generate(node)
end</code></pre>
</div>

]]></content>
  </entry>
  
</feed>
